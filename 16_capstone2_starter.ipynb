{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc67eabb-3bcd-44a9-8625-7ee6aff6e5ec",
   "metadata": {},
   "source": [
    "# Capstone project: Classify robot failures\n",
    "### Optional challenge: read the raw data files and format them correctly to save as CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1015d49-29d6-4fb5-834d-8d9d4e41c8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write code to read data files and format as CSV here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e319547d-40da-4814-8dee-06d587b43d49",
   "metadata": {},
   "source": [
    "## 1. Initial setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18acab5-e9c9-46b5-9701-5369648579b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, precision_recall_fscore_support \n",
    "\n",
    "from sktime.classification.dictionary_based import WEASEL\n",
    "from sktime.classification.ensemble import BaggingClassifier\n",
    "from sktime.classification.feature_based import SummaryClassifier, Catch22Classifier\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "\n",
    "from tsfresh import extract_features, select_features\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bfc911-fa1e-4187-80e4-c054e72515ed",
   "metadata": {},
   "source": [
    "### Read data (lp1 data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2168cac6-3444-40f7-a53c-2e42bac1e2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('data/lp1_X.csv')\n",
    "y = pd.read_csv('data/lp1_y.csv').squeeze()\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa70ff34-5481-4ec1-843c-284aeb994d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.set_index(['id', 'timestep'])\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b5af67-c01c-4793-bd19-1d79732fa19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49017be7-25d7-4346-a471-27d2912f2c41",
   "metadata": {},
   "source": [
    "### Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba9f310-b205-49b0-aea8-8c6ab84bdf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get index of each label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7464da97-377f-4577-b514-f91b943460b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get train/test split indices for each label and concatenate\n",
    "# all train and test indices together\n",
    "\n",
    "print(train_index)\n",
    "print(test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa70a31-0787-4698-b8af-3db26b0c5ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e3d880-31e4-45d7-bffd-2b42d8f9fb69",
   "metadata": {},
   "source": [
    "## 2. Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8906a657-1494-4838-b032-0b1b2da4935f",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {\n",
    "    'obstruction': 0,\n",
    "    'normal': 1,\n",
    "    'collision': 2,\n",
    "    'fr_collision': 3\n",
    "}\n",
    "\n",
    "# Map the labels to integers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2515b3-1651-440f-a261-b21e810064ab",
   "metadata": {},
   "source": [
    "### Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3d1955-f7cd-47ea-807e-4004102b8da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use bagging with WEASEL\n",
    "# Store the precision, recall and F1-Score\n",
    "# Print out the classification report\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16909df1-de85-44e5-bdd4-503023eab0fd",
   "metadata": {},
   "source": [
    "### Summary classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5f2065-8450-4bcd-b375-8d61447763b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Summary Classifier with a list of sklearn classifiers\n",
    "# For all models, print the precision, recall, and F1-Score\n",
    "# Which model performed best?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee59ab7-4d62-4f1a-8b2d-0b35f0b0cfb2",
   "metadata": {},
   "source": [
    "### TSFresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e14406c-bf14-4c37-b94a-b8a15064fea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('data/lp1_X.csv')\n",
    "y = pd.read_csv('data/lp1_y.csv').squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e0b801-2b9b-49d4-840b-0dbb22f5bb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features\n",
    "X_feat = extract_features(X, column_id='id', column_sort='timestep')\n",
    "X_feat = X_feat.dropna(axis=1)\n",
    "\n",
    "# Train/test split. Use the same indices as above\n",
    "X_train, y_train = X_feat.iloc[train_index], y.iloc[train_index]\n",
    "X_test, y_test = X_feat.iloc[test_index], y.iloc[test_index]\n",
    "\n",
    "# Filter features\n",
    "X_train_filtered = select_features(X_train, y_train, multiclass=True, n_significant=1)\n",
    "X_test_filtered = X_test[X_train_filtered.columns]\n",
    "\n",
    "# Define a list of sklearn classifiers\n",
    "classifiers = [knn_clf, ada_clf, rf_clf, svc_clf]\n",
    "\n",
    "# For each classifier, fit and print out the precision, recall and F1-Score\n",
    "# Which model performed best?\n",
    "for classifier in classifiers:\n",
    "       \n",
    "    classifier.fit(X_train_filtered, y_train)\n",
    "    \n",
    "    y_pred = classifier.predict(X_test_filtered)\n",
    "    \n",
    "    precision, recall, fscore, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    print(f\"Precision {precision} \\nRecall: {recall} \\nF1-Score: {fscore} \\n===================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d047ec00-ce0e-4167-8bea-4bbfde506288",
   "metadata": {},
   "source": [
    "## 3. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7159e5cd-6ce3-4cda-ab14-7b8f7d1ae6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a bar plot of F1-Scores for each method that we tried\n",
    "\n",
    "x = ['Bagging (WEASEL)', 'Summary (Random forest)', 'TSFresh (Random forest)']\n",
    "y = [0.50, 0.73, 0.81]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(x, y)\n",
    "ax.set_xlabel('Model')\n",
    "ax.set_ylabel('F1-Score (weighted)')\n",
    "ax.set_ylim(0, 1)\n",
    "\n",
    "for i, v in enumerate(y):\n",
    "    ax.text(x=i, y=v+0.05, s=str(v), ha='center')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c1fe75-1389-4f87-980c-a4cb85658f79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
